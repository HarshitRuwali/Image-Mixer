{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "9bab7d1fb54866d80f6fc3127ccf428772c5ab7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "48f3a236922c8a1d85fdc6efd68669eaee8ff919"
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "ITERATIONS = 10\n",
    "CHANNELS = 3\n",
    "IMAGE_SIZE = 500\n",
    "IMAGE_WIDTH = IMAGE_SIZE\n",
    "IMAGE_HEIGHT = IMAGE_SIZE\n",
    "IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n",
    "CONTENT_WEIGHT = 0.02\n",
    "STYLE_WEIGHT = 4.5\n",
    "TOTAL_VARIATION_WEIGHT = 0.995\n",
    "TOTAL_VARIATION_LOSS_FACTOR = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f86b73d5096c14604fb0db7b4bf5f906248a5b6d"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "input_image_path = \"input.png\"\n",
    "style_image_path = \"style.png\"\n",
    "output_image_path = \"output.png\"\n",
    "combined_image_path = \"combined.png\"\n",
    "\n",
    "# San Francisco\n",
    "san_francisco_image_path = \"https://www.economist.com/sites/default/files/images/print-edition/20180602_USP001_0.jpg\"\n",
    "\n",
    "# Warsaw by Tytus Brzozowski, http://t-b.pl\n",
    "tytus_image_path = \"http://meetingbenches.com/wp-content/flagallery/tytus-brzozowski-polish-architect-and-watercolorist-a-fairy-tale-in-warsaw/tytus_brzozowski_13.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b1b8dfb7d3af18a821ff92199c7c77279f91e095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=500x500 at 0x7FD2CF6019B0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input visualization \n",
    "input_image = Image.open(BytesIO(requests.get(san_francisco_image_path).content))\n",
    "input_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "input_image.save(input_image_path)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c67eef921eb800f15775b8570badbe5ac5b5b81b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=500x500 at 0x7FD2CF22E898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Style visualization \n",
    "style_image = Image.open(BytesIO(requests.get(tytus_image_path).content))\n",
    "style_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "style_image.save(style_image_path)\n",
    "style_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "01072f7aa15c4149fd5b342ae60e83f139b5487a"
   },
   "outputs": [],
   "source": [
    "# Data normalization and reshaping from RGB to BGR\n",
    "input_image_array = np.asarray(input_image, dtype=\"float32\")\n",
    "input_image_array = np.expand_dims(input_image_array, axis=0)\n",
    "input_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "input_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "input_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "input_image_array = input_image_array[:, :, :, ::-1]\n",
    "\n",
    "style_image_array = np.asarray(style_image, dtype=\"float32\")\n",
    "style_image_array = np.expand_dims(style_image_array, axis=0)\n",
    "style_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "style_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "style_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "style_image_array = style_image_array[:, :, :, ::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6dce8666aa5d2dc12c5d3f5b7cd68430ba843281"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "input_image = backend.variable(input_image_array)\n",
    "style_image = backend.variable(style_image_array)\n",
    "combination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3))\n",
    "\n",
    "input_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\n",
    "model = VGG16(input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "d21c94071256a83487f1b46c6d30b49d2dc3c106"
   },
   "outputs": [],
   "source": [
    "def content_loss(content, combination):\n",
    "    return backend.sum(backend.square(combination - content))\n",
    "\n",
    "layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "content_layer = \"block2_conv2\"\n",
    "layer_features = layers[content_layer]\n",
    "content_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "loss = backend.variable(0.)\n",
    "loss = loss + CONTENT_WEIGHT * content_loss(content_image_features,\n",
    "                                      combination_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "bbdd51f95c99b24ef2f288d2cad8039803d80aca"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b50fc77d82eafcf9526532f21fe51e8238b8b6bc"
   },
   "outputs": [],
   "source": [
    "def compute_style_loss(style, combination):\n",
    "    style = gram_matrix(style)\n",
    "    combination = gram_matrix(combination)\n",
    "    size = IMAGE_HEIGHT * IMAGE_WIDTH\n",
    "    return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n",
    "\n",
    "style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n",
    "for layer_name in style_layers:\n",
    "    layer_features = layers[layer_name]\n",
    "    style_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    style_loss = compute_style_loss(style_features, combination_features)\n",
    "    loss += (STYLE_WEIGHT / len(style_layers)) * style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2ddfe1d5a68fba2d70f85073dc467e3b99a2744f"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n",
    "    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n",
    "\n",
    "loss += TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "b38c32eeeb4aa935b9fb3f60909630b8922e7d87"
   },
   "outputs": [],
   "source": [
    "outputs = [loss]\n",
    "outputs += backend.gradients(loss, combination_image)\n",
    "\n",
    "def evaluate_loss_and_gradients(x):\n",
    "    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "    outs = backend.function([combination_image], outputs)([x])\n",
    "    loss = outs[0]\n",
    "    gradients = outs[1].flatten().astype(\"float64\")\n",
    "    return loss, gradients\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def loss(self, x):\n",
    "        loss, gradients = evaluate_loss_and_gradients(x)\n",
    "        self._gradients = gradients\n",
    "        return loss\n",
    "\n",
    "    def gradients(self, x):\n",
    "        return self._gradients\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec471551faa64da16b96f110561db44e8d4ec249"
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n",
    "    print(\"Iteration %d completed with loss %d\" % (i, loss))\n",
    "    \n",
    "x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "x = x[:, :, ::-1]\n",
    "x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n",
    "x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n",
    "x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n",
    "x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "output_image = Image.fromarray(x)\n",
    "output_image.save(output_image_path)\n",
    "output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9dd55a5b31f84ca0a37e0314bb151d7fe7422be8"
   },
   "outputs": [],
   "source": [
    "# Visualizing combined results\n",
    "combined = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\n",
    "x_offset = 0\n",
    "for image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n",
    "    combined.paste(image, (x_offset, 0))\n",
    "    x_offset += IMAGE_WIDTH\n",
    "combined.save(combined_image_path)\n",
    "combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
